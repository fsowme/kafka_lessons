- Передавать и хранить сообщения можно разными способами:
    - Потоки данных
    - Очереди сообщений
    - Хранилище событий

- Потоки данных (Data Streams) - это последовательность событий, которые поступают в реальном времени и сразу
    обрабатываются по мере их поступления. Потоки данных ориентированы на непрерывную обработку, несколько консьюмеров
    параллельно считывают данные без потерь информации. В Kafka потоки данных организованы через топики, разделенные на
    партиции, которые позволяют консьюмерам читать сообщения одновременно. Для работы с потоками данных есть два
    инструмента:
        - Kafka Steams - встроенная библиотека для обработки потоков в реальном времени. С помощью нее создают сложные
            конвейеры обработки событий
        - Кластер Kafka - помогает распределять потоки по нескольким брокерам для поддержания масштабируемости

- Очередь сообщений (Message Queue) - это структура данных, в которой сообщения обрабатываются по принципу FIFO. Когда
    продюсер отправляет сообщение в очередь, оно ждет обработки. Каждое сообщение читает только один консьюмер, после
    этого сообщение удаляется. Основные свойства:
        - Сообщение читается одним получателем и затем удаляется
        - Подходит для асинхронных задач, где важна последовательная обработка
        - Гарантирует, что сообщение будет доставлено и обработано только один раз

- Хранилище событий (Event Store) - это система, которая сохраняет все события и дает возможность читать их несколько
    раз. Хранилище событий записывает события в журнал, консьюмеры читают их независимо друг от друга, в любое время и
    несколько раз

- Сводная информация:
    - Как работает:
        - Очереди сообщений - сообщения удаляются после обработки
        - Хранилище событий - сообщения хранятся долго, их можно читать много раз
        - Потоки данных - сообщения поступают непрерывно и обрабатываются сразу (иногда настраивают кратковременное
            хранение, если необходимо повторное чтение)
    - Как обрабатываются данные:
        - Очередь сообщений - последовательно (FIFO)
        - Хранилище событий - непосредственный доступ к данным (возможна параллельная работа)
        - Потоки данных - непрерывно
    - Когда подойдет:
        - Очередь сообщений - данные нужны один раз, потом их можно удалить
        - Хранилище событий - важна история данных и возможность многократного доступа
        - Потоки данных - важно непрерывно обрабатывать информацию и реагировать в реальном времени
    - Пример использования:
        - Очередь сообщений - асинхронные задачи между сервисами
        - Хранилище событий - аналитика, историческая статистика
        - Потоки данных - события в реальном времени (трекинг, мониторинг)

- Отказоустойчивость в Kafka достигается с помощью репликации данных. Создается несколько копий узлов на нескольких
    серверах, на каждом узле сохраняется актуальная информация. В случае сбоя на одном из узлов, система автоматически
    переключится на один из резервных узлов, где находится актуальная информация. Пример:
        - Брокер 1:
            - topic1-replica1
            - topic3-replica2
        - Брокер 2:
            - topic1-replica2
            - topic2-replica1
        - Брокер 3:
            - topic2-replica2
            - topic3-replica1

- Репликация бывает синхронная и асинхронная:
    - Синхронная - данные записываются на основной узел и одновременно отправляются на реплики. Данные успешно записаны
        только после того как запись подтверждена основным узлом и всеми репликами
        - Плюсы - данные всегда согласованы
        - Минусы - издержки при записи
    - Асинхронная - данные записываются на основной узел, а не реплики с какой-то задержкой. Данные не сразу достигают
        всех узлов, но со временем все же достигают. Данные согласованы в конечном счете, но не в любой момент, такая
        модель называется eventual consistency (консистентность в конечном счете)
            - Плюсы - уменьшение нагрузки на основной узел, данные записываются быстрее
            - Минусы - данные на репликах временно могут не совпадать

- Полная репликация - сохранение полных копий данных на всех реплицированных узлах
    - Плюсы - полная отказоустойчивость
    - Минусы - нужно очень много ресурсов

- В Kafka возможно применять индексацию, для ускорения доступа к данным и упрощения обработки. Индексация логов поможет
    системе быстрее восстанавливаться после сбоев => система станет более отказоустойчивой

- Каждая партиция топика имеет один лидер и несколько реплик

- Лидер принимает решения и синхронизирует все части системы, отвечает за все операции чтения и записи

- Реплика только копирует данные с лидера и может стать лидером при сбое на текущем

- Процесс репликации:
    - Запсь - данные поступают от продюсера и записываются на брокера, где находится лидер
    - Распространение - лидер партиции передает данные на все относящиеся к ней реплики
    - Подтверждение - реплики присылают подтверждение, что они записали данные
    - Лидер отдает успешный ответ клиенту
    - (Доп) Периодически обновляется состояние реплик - реплики опрашивают реплики для синхронизации, если есть новые
        данные, то реплика получает их. Если реплика долго не синхронизировалась, то отмечается в системе и в случае
        сбоя не сможет стать новым лидером
    - (Доп) Когда лидер выходит из строя, происходит обработка отказа. Система автоматически назначает одну из
        синхронизированных реплик новым лидером и начинает направлять все запросы на чтение и запись уже ей

- replication-factor=N - количество брокеров в репликации (реплик для каждой партиции)

- Настройки репликации, управляющие минимальным количеством подтверждений для завершения записи
    - acks - количество реплик, которые должны подтвердить запись (включая лидера)
    - min.insync.replicas - минимальное количество реплик в синхронном состоянии, которые должны подтвердить запись
        для выполнения успешной записи. Если выставить заниженное значение, данные сохранятся даже при неактивных
        репликах. Это снижает консистентность и противоречит самой идее репликации, данные должны быть синхронизированы

- Варианты acks
    - acks=0 - подтверждение не требуется, данные отправляются в трубу, нет гарантии, что данные вообще записаны, но
        система работает быстро
    - acks=1 - подтверждение требуется от одной реплики (лидера), но если лидер выйдет из строя, до того как сообщение
        будет реплицировано, то оно потеряется
    acks=N - подтверждение будет отправлено продюсеру после того как запись подтвердит лидер и N-1 реплик
    acks=all - подтверждение будет отправлено продюсеру после того как все реплики подтвердят запись

- Официальная документации указывает на то, что часто устанавливают
    - replication-factor=3
    - min.insync.replicas=2
    - acks=all
    Такой вариант считается золотой серединой, часто следует начать с него и далее ориентироваться на поведение
        конкретной системы

- Ключ партицирования - специальный атрибут (или набор), по которому выюбирается партиция

- Продюсер может устанавливать ключ партицирования, выбирая в какую партицию попадет сообщение

- Ключом может быть:
    - ID пользователя - все сообщения, относящиеся к одному пользователю, будут обрабатываться последовательно. Часто
        подходит для систем работающий с данными клиентов (например маркетплейс)
    - ID транзакции - полезно для систем, где важна целостность каждой транзакции (напрмер финансы)
    - Географическое местоположение - часто используется в системах логистики
    - Отсутствие ключа - если последовательно неважна, сообщения будут распределяться случайно, загружая партиции
        равномерно (например для систем логирования, сбора метрик)

- Ключи влияют на распределение нагрузки, некоторые использовать неэффективно (напрмер дата) => при выборе данных для
    ключа следует помнить об эффективности

- Чем больше партиций, тем больше возможностей обрабатывать данные параллельно => выше производительность и
    масштабируемость, а если у партиций есть реплики, то система продолжит работать и при сбое узлов

- Чем больше партиций, тем сложнее управлять, для них нужно больше дискового пространства и пропускной способности сети,
    а при сбоях процесс восстановления и синхронизации может занять больше времени

- Количество партиций влияет эффективность обработки данных, производительность системы, отказоустойчивость и затраты на
    ресурсы.

- При выборе количества партиций следует учитывать следующие факторы:
    - Количество консьюмеров - для параллельной обработки данных количество партиций должно быть не меньше количества
        консьюмеров
    - Объем данных - с ростом объема данных увеличивается и количество партиций
    - Особенности инфраструктуры - чем больше партиций, тем больше нагрузка на диск и сеть => если инфраструктура не
        позволяет повышать нагрузку, то и увеличивать количество партиций не имеет смысла

- Большое количество партиций подойдет, если ожидается большой поток данных и нужна высокая масштабируемость

- Малое количество партиций подойдет для сервисов с невысокой нагрузкой, где равномерное распределение некритично

- Кластеры Kafka настраиваются так, чтобы каждая партиция имела хотя бы одну реплику

- При сбое Kafka автоматически переназначает лидерство на одну из реплик

- Флоу при сбоях:
    - Поиск доступных реплик - система определяет все доступные реплики партиции из имеющихся узлов
    - Переназначения лидера - система выбирает одну из найденных реплик и назначает ее лидером, при этом консьюмеры не
        прекращают свою работу и не замечают переключения
    - Восстановление - когда первоначальный узел восстановлен, оригинальная партиция возвращается в строй, kafka
        синхронизирует восстановленную партицию с текущеми данными

- Чем хороши партиции:
    - Распределяют данные между узлами кластера, что повышает пропускную способность системы
    - Структурируют и разделяют данные, так как удобнее для приложения
    - Позволяют обрабатывать данные параллельно, что критично для масштабируемых и высоконагруженных систем
    - Обеспечивают отказоустойчивость с помощью репликации партиций, если узел выходит из строя, то лидерство передается
        другим репликам

- Типы масштабирования:
    - Вертикальное - увеличение мощности серверов
    - Горизонтальное - увеличение количества серверов

- Плюсы горизонтального масштабирования
    - Гибкость - можно добавлять узлы в кластер, не прерывая его работу
    - Отказоустойчивость - если один узел выходит из строя, другие продолжают работу
    - Высокая производительность - когда узлов и партиций много, нагрузка распределяется между ними

- Основные варианты масштабирования Kafka
    - Новые брокеры в кластер - брокер управляет несколькими топиками, при добавлении нового нагрузка на текущие
        снижается. Решение распределит нагрузку на сеть, данные будут храниться на разных серверах. Вариант подойдет
        для повышения устойчивости кластера к перегрузкам
    - Новые партиции для топика - можно распределить нагрузку на большее количество консьюмеров, что увеличит пропускную
        способность системы. Необходимо планировать заранее, тк на время конфигурирование систему, может быть, придется
        остановить

Частые ошибки
    - Создали недостаточное кол-во реплик - если кластер увеличивает без добавления реплик, то теряется
        отказоустойчивость. При сбое узла данные будет недоступны, тк не зватит реплик для замещения
    - Неверно выбрали кол-во партиций - если создать очень много, то Kafka придется управлять слишком большим
        количеством метаданных
