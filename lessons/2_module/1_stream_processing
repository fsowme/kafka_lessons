- Потоковая обработка (Stream Processing) - обработка данных по мере того, как они поступают (в реальном времени)

- Отличия потоковой обработки и пакетной:
    - Время обработки:
        - Пакетная - по расписанию (например ежедневно)
        - Потоковая - в режиме реального времени
    - Задержка:
        - Пакетная - высокая, отложенная
        - Потоковая - низкая, минимальная
    - Подходит для задач:
        - Пакетная - аналитика, отчеты, агрегирование данных
        - Потоковая - реагирование на события, мониторинг
    - Примеры применения:
        - Пакетная - финансовые отчеты, архивные данные
        - Потоковая - аналитика кликов, отслеживание позиций
    - Итог:
        - Пакетная - для обработки крупных объемов данных с допустимой задержкой
        - Потоковая - для оперативной обработки и реакции на данные

- Для потоковой обработки в Kafka имеется два инструмента:
    - Kafka Streams
    - KSQL

- Kafka Streams - клиентское приложение для построения приложений на базе Kafka. Позволяет писать приложения на Java и
    Scala, которые могут читать из Kafka, обрабатывать из и записывать обратно

- Общий процесс - producer отправляет данные в Kafka Cluster, который содержит топики. Эти топики выступают в роли
    каналов. Kafka Streams получает потоки (Streams) из этих топиков, обрабатывает, применяя потоковые операции, такие
    как фильтрация, агрегация и объединение данных. После обработки результат возвращается обратно в Kafka, откуда
    его может забрать consumer

                | Kafka Cluster |    | Kafka Streams |
    Producer -> |  topic 1      | -> |               |
             -> |  topic 2      | -> |               |
                |               |    |               |
    Consumer <- |  topic n      | <- |               |

- Преимущества Kafka Streams:
    - Интеграция с приложением - реализация потоковой обработки на стороне Java/Scala приложения
    - Высокая производительность - позволяет обрабатывать большие объемы с низкой задержкой
    - Stateful обработка - поддерживает сложные операции с сохранением состояния (например, агрегирование и соединение
        потоков)
    - Масштабируемость и отказоустойчивость - автоматически масштабируется, обеспечивая высокую доступность без
        дополнительных настроек, данные могут быть восстановлены при системных сбоях

- Faust - python-библиотека для потоковой обработки данных. Имеет много архитектурных сходств с Kafka Streams

- App - центральный объект в Faust, представляющий собой интерфейс для потоковой обработки. Тут настраивается
    подключение к Kafka, определяются задачи обработки и конфиг приложения

- Agent - асинхронная функция, обеспечивающая все трансформации данных из топика. В реальном времени он обрабатывает все
    элементы потока, применяя к данным все операции. Ключевой элемент Faust, аналог Stream Processor в Kafka Streams

- Stream - поток записей, поступающий из Kafka-топиков, представляющий последовательность событий. Аналог KStream в
    Kafka Stream

- Sink - функция, которая используется для выполнения действий после того, как Agent обработал событие в потоке

- Table - таблица состояний, хранящая состояния данных (последние данные для каждого ключа) с возможностью
    обновления. Аналог KTable в Kafka Streams

- Serializer/Deserializer - компоненты, отвечающие за преобразование данных в байтовый формат и обратно

- KSQL - интерфейс, позволяющий выполнять потоковую обработку данных с помощью SQL-подобных запросов

- KSQLDB - система потоковой обработки событий, основанная на архитектура клиент-сервер, взаимодействует с данными в
    топиках через SQL-подобный интерфейс

- KSQLDB позволяет:
    - Запросы получения данных на конкретный момент времени
    - Объединять управление данными из разных источников

- KSQLDB позволяет с помощью SQL работать как с потоками событий, так и состоянием объектов

- KSQLDB позволяет интегрировать множество источников данных (БД, файловые системы и другие системы обработки данных), в
    качестве потребителей поддерживает не только Kafka, но и пользовательские сервисы, что дает гибкость в обработке и
    анализе данных в реальном времени

- Сравнение KSQL и Faust:
    - Язык разработки:
        - KSQL - SQL-подобный
        - Faust - python
    - Гибкость:
        - KSQL - ограничена sql
        - Faust - высокая
    - Сложность разработки:
        - KSQL - средняя - высокая (требуется знаение языка python)
        - Faust - низкая - средняя (декларативный подход, проще начать работу)
    - Обработка данных:
        - KSQL - только стриминговая, но в ksqlDB возможно через материализованные представленмя
        - Faust - стриминговая и обработка состояний (stateful processing, например, join или агрегации)
    - Хранение состояния:
        - KSQL - нет, только операции с потоками
        - Faust - локальное (memory://, rocksdb://), синхронизируемое через Kafka (changelog)

- Faust поддерживает два подхода:
    - Stateless - каждое сообщение обрабатывается независимо от остальных, обработка не зависит от сохранения информации
        о предыдущих сообщениях. Например, когда надо только фильтровать или преобразовывать сообщения. Stateless легок
        и упрощает масштабирование
    - Stateful - сохранение контекста обработки, Faust позволяет сохранять промежуточные состояния в локальных
        хранилищах или синхронизировать его с Kafka для отказоустойчивости. Например при подсчете количества событий за
        определенное время или агригирования данных

- Оконная агрегация (Windowing) - позволяет обрабатывать потоки данных, сохраняя состояния в пределах заданных временных
    окон. Оконная таблица хранит пары "ключ-значение" в соответствии с политикой windowing

- Faust реализует два типа оконной агрегации:
    - Tumbling window (статичное окно) - фиксированные и не пересекающиеся промежутки времени. Например: 10-секундные
        окна
    - Hopping window (перекрывающееся окно) - фиксированные интервалы времени, которые пересекаются. Например, окна
        длиной 10 секунд, создаваемые каждые 5 секунд

- Основные функции агента Faust:
    - Чтение сообщений из топика - агент подписывается на топики Kafka
    - Обработка сообщений - внутри функции выполняется трансформация данных
    - Запись обработанных данных - результаты записываются в выходные топики или обновляют таблицы

- Характеристики и задачи  Stream:
    - Бесконечный источник данных - потоки работают с данными, поступающими в реальном времени и без заранее
        определенного завершения
    - Десериализация сообщений - при итерации по потоку сообщения автоматически преобразуются из байтов в объект модели
        данных
    - Гибкость работы с данными:
        - Возможность работать с ключами и значениями (stream.items())
        - Доступ к сырым сообщениям (stream.events())

- Дополнительные возможности потоков:
    - Операции над потоками:
        - group_by() - перераспределение на основе ключа
        - filter() - фильтрация перед обработкой
        - take() - сбор группы сообщений перед обработкой
    - Комбинирование потоков - обработка нескольких потоков одновременно (async for value in (strean1 & stream2))
    - Гарантия обработки - автоматическое или ручное подтверждение обработки (event.ack())

- Processor (Обработчик) - механизм, позволяющий в потоке применять к сообщениям набор функций для трансформации

- Принцип работы Processor:
    - Принимает значение в качестве аргумента
    - Возвращает модифицированное значение
    - Применяются в порядке их добавления
    - Могут быть синхронными или асинхронными

- Sink - механизм, позволяющий выполнять действия над событиями уже после их обработки

- Преимущества Sink:
    - Интеграция с внешними системами - легко интегрировать агент с мониторингом, аналитикой или алертингом
    - Гибкость в построении потоков - позволяет строить сложные цепочки обработки событий, передавая данные между
        агентами или в разные топики
    - Повышение читаемости и тестируемости - разделение логики обработки событий и постобработки повышает модульность
        кода, его легче тестировать

- Типы функций Sink:
    - Callback function (Функция обратного вызова) - функция будет вызвана после каждого события, может быть синхронной
        и асинхронной:
        - Sync:
            def log(value): print(f'Processed {value}')

            @app.agent(sink=[log])
            def process(stream): ...

        - Async:
            async def some(value): await ...

            @app.agent(sink=[some])
            async def process(stream): ...

    - Топик Kafka - отправка обработанных сообщений в другой топик Kafka:
        another_topic = app.topic('another-topic')

        @app.agent(sink=[another_topic])
        async def some(stream): ...

    - Другой агент Faust - события могут быть автоматически переданы другому агенту для дальнейшей обработки:
        @app.agent()
        async def second(stream): ...

        @app.agent(sink=[second])
        async def first(stream): ...

- Faust поддерживает два вида хранения данных:
    - In-memory - данные хранятся в памяти, доступ быстрый, не сохраняются при перезапуске
    - Persistent - данные хранятся на диске в RocksDB, долговременное хранение, но медленнее чем в памяти
